@misc{placeholder,
  title     = {Placeholder Title},
  author    = {First Author and Second Author},
  year      = {2025},
  note      = {To be updated},
}
@misc{todo,
  title     = {to-do},
  author    = {to-do},
  year      = {2025},
  note      = {To be updated},
}

%%%% Other %%%%
@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}
@misc{whisper,
  title={Robust Speech Recognition via Large-Scale Weak Supervision}, 
  author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
  year={2022},
  eprint={2212.04356},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url={https://arxiv.org/abs/2212.04356}, 
}
@misc{kwon2023efficientmemorymanagementlarge,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention}, 
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  year={2023},
  eprint={2309.06180},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2309.06180}, 
}
@misc{wolf2020huggingfacestransformersstateoftheartnatural,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
  year={2020},
  eprint={1910.03771},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1910.03771}, 
}
@misc{apache_parquet,
  title        = {Apache Parquet: A Columnar Storage File Format},
  howpublished = {\url{https://parquet.apache.org}},
  note         = {Accessed: YYYY‐MM‐DD},
  year         = {2013},
  organization = {Apache Software Foundation}
}
@misc{cheng2023batchpromptingefficientinference,
  title={Batch Prompting: Efficient Inference with Large Language Model APIs}, 
  author={Zhoujun Cheng and Jungo Kasai and Tao Yu},
  year={2023},
  eprint={2301.08721},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2301.08721}, 
}
@misc{balestriero2023cookbookselfsupervisedlearning,
  title={A Cookbook of Self-Supervised Learning}, 
  author={Randall Balestriero and Mark Ibrahim and Vlad Sobal and Ari Morcos and Shashank Shekhar and Tom Goldstein and Florian Bordes and Adrien Bardes and Gregoire Mialon and Yuandong Tian and Avi Schwarzschild and Andrew Gordon Wilson and Jonas Geiping and Quentin Garrido and Pierre Fernandez and Amir Bar and Hamed Pirsiavash and Yann LeCun and Micah Goldblum},
  year={2023},
  eprint={2304.12210},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2304.12210}, 
}
@misc{chen2020simpleframeworkcontrastivelearning,
  title={A Simple Framework for Contrastive Learning of Visual Representations}, 
  author={Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey Hinton},
  year={2020},
  eprint={2002.05709},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2002.05709}, 
}
@misc{galton_1886_1449548,
  author       = {Galton, Francis},
  title        = {Regression Towards Mediocrity in Hereditary Stature.},
  month        = jan,
  year         = 1886,
  publisher    = {Zenodo},
  doi          = {10.2307/2841583},
  url          = {https://doi.org/10.2307/2841583},
}

%%%% CEFR %%%%
@book{CouncilOfEurope2001CEFR,
  title = {Common European Framework of Reference for Languages: Learning, Teaching, Assessment},
  author = {{Council of Europe}},
  year = {2001},
  publisher = {Cambridge University Press},
  address = {Cambridge}
}
@misc{cambridge2020linguaskill,
  title        = {Linguaskill Speaking Global Assessment Criteria},
  author       = {{Cambridge English}},
  year         = {2020},
  howpublished = {\url{https://www.cambridgeenglish.org/Images/605504-linguaskill-speaking-assessment-criteria.pdf}},
  note         = {Accessed: 2025-09-10}
}

%%%% SLA %%%%
% Historical SLA
@inproceedings{bernstein90_icslp,
  title     = {Automatic evaluation and training in English pronunciation},
  author    = {Jared Bernstein and Michael Cohen and Hy Murveit and Dimitry Rtischev and Mitchel Weintraub},
  year      = {1990},
  booktitle = {First International Conference on Spoken Language Processing (ICSLP 1990)},
  pages     = {1185--1188},
  doi       = {10.21437/ICSLP.1990-313},
  issn      = {2958-1796},
}
@inproceedings{qian12c_interspeech,
  title     = {The use of DBN-HMMs for mispronunciation detection and diagnosis in L2 English to support computer-aided pronunciation training},
  author    = {Xiaojun Qian and Helen Meng and Frank K. Soong},
  year      = {2012},
  booktitle = {Interspeech 2012},
  pages     = {775--778},
  doi       = {10.21437/Interspeech.2012-238},
  issn      = {2958-1796},
}
% BERT-based SLA
@misc{devlin2019bertpretrainingdeepbidirectional,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year={2019},
  eprint={1810.04805},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1810.04805}, 
}
@misc{yang2020xlnetgeneralizedautoregressivepretraining,
  title={XLNet: Generalized Autoregressive Pretraining for Language Understanding}, 
  author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
  year={2020},
  eprint={1906.08237},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1906.08237}, 
}
@INPROCEEDINGS{bert_1,
  author={Wang, Xinhao and Evanini, Keelan and Qian, Yao and Mulholland, Matthew},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Automated Scoring of Spontaneous Speech from Young Learners of English Using Transformers}, 
  year={2021},
  volume={},
  number={},
  pages={705-712},
  keywords={Support vector machines;Vocabulary;Recurrent neural networks;Speech;Robustness;Grammar;Task analysis;Automatic spoken language assessment;children’s non-native spontaneous speech;Transformer},
  doi={10.1109/SLT48900.2021.9383553}
}
@inproceedings{raina20_interspeech,
  title     = {Universal Adversarial Attacks on Spoken Language Assessment Systems},
  author    = {Vyas Raina and Mark J.F. Gales and Kate M. Knill},
  year      = {2020},
  booktitle = {Interspeech 2020},
  pages     = {3855--3859},
  doi       = {10.21437/Interspeech.2020-1890},
  issn      = {2958-1796},
}
% End-to-end SLA
@misc{baevski2020wav2vec20frameworkselfsupervised,
  title={wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations}, 
  author={Alexei Baevski and Henry Zhou and Abdelrahman Mohamed and Michael Auli},
  year={2020},
  eprint={2006.11477},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2006.11477}, 
}
@misc{hsu2021hubertselfsupervisedspeechrepresentation,
  title={HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units}, 
  author={Wei-Ning Hsu and Benjamin Bolte and Yao-Hung Hubert Tsai and Kushal Lakhotia and Ruslan Salakhutdinov and Abdelrahman Mohamed},
  year={2021},
  eprint={2106.07447},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2106.07447}, 
}
@misc{bannò2022proficiencyassessmentl2spoken,
  title={Proficiency assessment of L2 spoken English using wav2vec 2.0}, 
  author={Stefano Bannò and Marco Matassoni},
  year={2022},
  eprint={2210.13168},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2210.13168}, 
}
@misc{bannò2022l2proficiencyassessmentusing,
  title={L2 proficiency assessment using self-supervised speech representations}, 
  author={Stefano Bannò and Kate M. Knill and Marco Matassoni and Vyas Raina and Mark J. F. Gales},
  year={2022},
  eprint={2211.08849},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url={https://arxiv.org/abs/2211.08849}, 
}
@article{mcknight_civelekoglu_gales_banno_liusie_knill_2023, 
  title={Automatic Assessment of Conversational Speaking Tests}, 
  url={https://www.repository.cam.ac.uk/handle/1810/353637}, 
  DOI={10.17863/CAM.99725}, 
  publisher={Apollo - University of Cambridge Repository}, 
  author={McKnight, Simon Webster and Civelekoglu, Arda and Gales, Mark JF and Banno, Stefano and Liusie, Adian and Knill, Kate M}, 
  year={2023}
}
% Audio LLM SLA
@article{ma2025assessment,
  title={Assessment of L2 Oral Proficiency using Speech Large Language Models},
  author={Ma, Rao and Qian, Mengjie and Tang, Siyuan and Bannò, Stefano and Knill, Kate M. and Gales, Mark J.F.},
  journal={arXiv preprint arXiv:2505.21148},
  year={2025},
  url={https://arxiv.org/abs/2505.21148}
}
@article{knill2024sandi,
  title={Speak \& Improve Corpus 2025: an L2 English Speech Corpus for Language Assessment and Feedback},
  author={Knill, Kate and Nicholls, Diane and Gales, Mark J.F. and Qian, Mengjie and Stroinski, Pawel},
  journal={arXiv preprint arXiv:2412.11986},
  year={2024},
  url={https://arxiv.org/abs/2412.11986}
}
@article{qian2024sandi,
  title={Speak \& Improve Challenge 2025: Tasks and Baseline Systems},
  author={Qian, Mengjie and Knill, Kate and Bannò, Stefano and Tang, Siyuan and Karanasou, Penny and Gales, Mark J.F. and Nicholls, Diane},
  journal={arXiv preprint arXiv:2412.11985},
  year={2024},
  url={https://arxiv.org/abs/2412.11985}
}
@book{Ludlow2020OfficialQuick,
  author = {Ludlow, Karen},
  title = {Official Quick Guide to Linguaskill},
  publisher = {Cambridge University Press},
  year = {2020},
  isbn = {978-1108885256}
}
@misc{liusie2023mitigatingwordbiaszeroshot,
      title={Mitigating Word Bias in Zero-shot Prompt-based Classifiers}, 
      author={Adian Liusie and Potsawee Manakul and Mark J. F. Gales},
      year={2023},
      eprint={2309.04992},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.04992}, 
}

%%%% Audio LLMs %%%%
@misc{radford2022robustspeechrecognitionlargescale,
      title={Robust Speech Recognition via Large-Scale Weak Supervision}, 
      author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
      year={2022},
      eprint={2212.04356},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2212.04356}, 
}
@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}
@misc{rubenstein2023audiopalmlargelanguagemodel,
  title={AudioPaLM: A Large Language Model That Can Speak and Listen}, 
  author={Paul K. Rubenstein and Chulayuth Asawaroengchai and Duc Dung Nguyen and Ankur Bapna and Zalán Borsos and Félix de Chaumont Quitry and Peter Chen and Dalia El Badawy and Wei Han and Eugene Kharitonov and Hannah Muckenhirn and Dirk Padfield and James Qin and Danny Rozenberg and Tara Sainath and Johan Schalkwyk and Matt Sharifi and Michelle Tadmor Ramanovich and Marco Tagliasacchi and Alexandru Tudor and Mihajlo Velimirović and Damien Vincent and Jiahui Yu and Yongqiang Wang and Vicky Zayats and Neil Zeghidour and Yu Zhang and Zhishuai Zhang and Lukas Zilka and Christian Frank},
  year={2023},
  eprint={2306.12925},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2306.12925}, 
}
@misc{tang2024salmonngenerichearingabilities,
  title={SALMONN: Towards Generic Hearing Abilities for Large Language Models}, 
  author={Changli Tang and Wenyi Yu and Guangzhi Sun and Xianzhao Chen and Tian Tan and Wei Li and Lu Lu and Zejun Ma and Chao Zhang},
  year={2024},
  eprint={2310.13289},
  archivePrefix={arXiv},
  primaryClass={cs.SD},
  url={https://arxiv.org/abs/2310.13289}, 
}
@misc{chu2023qwenaudioadvancinguniversalaudio,
  title={Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models}, 
  author={Yunfei Chu and Jin Xu and Xiaohuan Zhou and Qian Yang and Shiliang Zhang and Zhijie Yan and Chang Zhou and Jingren Zhou},
  year={2023},
  eprint={2311.07919},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url={https://arxiv.org/abs/2311.07919}, 
}
@misc{chu2024qwen2audiotechnicalreport,
  title={Qwen2-Audio Technical Report}, 
  author={Yunfei Chu and Jin Xu and Qian Yang and Haojie Wei and Xipin Wei and Zhifang Guo and Yichong Leng and Yuanjun Lv and Jinzheng He and Junyang Lin and Chang Zhou and Jingren Zhou},
  year={2024},
  eprint={2407.10759},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url={https://arxiv.org/abs/2407.10759}, 
}
@misc{ghosh2024gamalargeaudiolanguagemodel,
  title={GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities}, 
  author={Sreyan Ghosh and Sonal Kumar and Ashish Seth and Chandra Kiran Reddy Evuru and Utkarsh Tyagi and S Sakshi and Oriol Nieto and Ramani Duraiswami and Dinesh Manocha},
  year={2024},
  eprint={2406.11768},
  archivePrefix={arXiv},
  primaryClass={cs.SD},
  url={https://arxiv.org/abs/2406.11768}, 
}
@misc{microsoft2025phi4minitechnicalreportcompact,
  title={Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs}, 
  author={Microsoft and : and Abdelrahman Abouelenin and Atabak Ashfaq and Adam Atkinson and Hany Awadalla and Nguyen Bach and Jianmin Bao and Alon Benhaim and Martin Cai and Vishrav Chaudhary and Congcong Chen and Dong Chen and Dongdong Chen and Junkun Chen and Weizhu Chen and Yen-Chun Chen and Yi-ling Chen and Qi Dai and Xiyang Dai and Ruchao Fan and Mei Gao and Min Gao and Amit Garg and Abhishek Goswami and Junheng Hao and Amr Hendy and Yuxuan Hu and Xin Jin and Mahmoud Khademi and Dongwoo Kim and Young Jin Kim and Gina Lee and Jinyu Li and Yunsheng Li and Chen Liang and Xihui Lin and Zeqi Lin and Mengchen Liu and Yang Liu and Gilsinia Lopez and Chong Luo and Piyush Madan and Vadim Mazalov and Arindam Mitra and Ali Mousavi and Anh Nguyen and Jing Pan and Daniel Perez-Becker and Jacob Platin and Thomas Portet and Kai Qiu and Bo Ren and Liliang Ren and Sambuddha Roy and Ning Shang and Yelong Shen and Saksham Singhal and Subhojit Som and Xia Song and Tetyana Sych and Praneetha Vaddamanu and Shuohang Wang and Yiming Wang and Zhenghao Wang and Haibin Wu and Haoran Xu and Weijian Xu and Yifan Yang and Ziyi Yang and Donghan Yu and Ishmam Zabir and Jianwen Zhang and Li Lyna Zhang and Yunan Zhang and Xiren Zhou},
  year={2025},
  eprint={2503.01743},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2503.01743}, 
}
@misc{xu2025qwen25omnitechnicalreport,
  title={Qwen2.5-Omni Technical Report}, 
  author={Jin Xu and Zhifang Guo and Jinzheng He and Hangrui Hu and Ting He and Shuai Bai and Keqin Chen and Jialin Wang and Yang Fan and Kai Dang and Bin Zhang and Xiong Wang and Yunfei Chu and Junyang Lin},
  year={2025},
  eprint={2503.20215},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2503.20215}, 
}
@misc{sakshi2024mmaumassivemultitaskaudio,
      title={MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark}, 
      author={S Sakshi and Utkarsh Tyagi and Sonal Kumar and Ashish Seth and Ramaneswaran Selvakumar and Oriol Nieto and Ramani Duraiswami and Sreyan Ghosh and Dinesh Manocha},
      year={2024},
      eprint={2410.19168},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2410.19168}, 
}

%%%% Mispronunciation Detection and Diagnosis (MDD) %%%%
@inproceedings{peng21e_interspeech,
  title     = {A Study on Fine-Tuning wav2vec2.0 Model for the Task of Mispronunciation Detection and Diagnosis},
  author    = {Linkai Peng and Kaiqi Fu and Binghuai Lin and Dengfeng Ke and Jinsong Zhan},
  year      = {2021},
  booktitle = {Interspeech 2021},
  pages     = {4448--4452},
  doi       = {10.21437/Interspeech.2021-1344},
  issn      = {2958-1796},
}
@inproceedings{inproceedings_wu_mdd,
  author = {Wu, Minglin and Li, Kun and Leung, Wai-Kim and Meng, Helen},
  year = {2021},
  month = {08},
  pages = {3954-3958},
  title = {Transformer Based End-to-End Mispronunciation Detection and Diagnosis},
  doi = {10.21437/Interspeech.2021-1467}
}
@inproceedings{xu21k_interspeech,
  title     = {Explore wav2vec 2.0 for Mispronunciation Detection},
  author    = {Xiaoshuo Xu and Yueteng Kang and Songjun Cao and Binghuai Lin and Long Ma},
  year      = {2021},
  booktitle = {Interspeech 2021},
  pages     = {4428--4432},
  doi       = {10.21437/Interspeech.2021-777},
  issn      = {2958-1796},
}
@misc{kim2022automaticpronunciationassessmentusing,
  title={Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning}, 
  author={Eesung Kim and Jae-Jin Jeon and Hyeji Seo and Hoon Kim},
  year={2022},
  eprint={2204.03863},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url={https://arxiv.org/abs/2204.03863}, 
}
@misc{fu2024pronunciationassessmentmultimodallarge,
  title={Pronunciation Assessment with Multi-modal Large Language Models}, 
  author={Kaiqi Fu and Linkai Peng and Nan Yang and Shuran Zhou},
  year={2024},
  eprint={2407.09209},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2407.09209}, 
}

%%%% Automatic Essay Scoring (AES) %%%%
% Historical AES
@article{page1966,
  ISSN = {00317217},
  URL = {http://www.jstor.org/stable/20371545},
  author = {Ellis B. Page},
  journal = {The Phi Delta Kappan},
  number = {5},
  pages = {238--243},
  publisher = {Phi Delta Kappa International},
  title = {The Imminence of... Grading Essays by Computer},
  urldate = {2025-09-10},
  volume = {47},
  year = {1966}
}
% Initial AES
@misc{gpt3,
  title={Language Models are Few-Shot Learners}, 
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year={2020},
  eprint={2005.14165},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2005.14165}, 
}
@article{aes_gpt3,
  title = "Exploring the potential of using an AI language model for automated essay scoring",
  keywords = "Automated essay scoring (AES), GPT (Generative Pre-trained Transformer), Linguistic features, Natural language processing (NLP), Transformer-based large language models",
  author = "Atsushi Mizumoto and Masaki Eguchi",
  note = "Publisher Copyright: {\textcopyright} 2023 The Author(s)",
  year = "2023",
  month = aug,
  doi = "10.1016/j.rmal.2023.100050",
  language = "English",
  volume = "2",
  journal = "Research Methods in Applied Linguistics",
  issn = "2772-7661",
  publisher = "Elsevier B.V.",
  number = "2",
}
@inproceedings{yancey-etal-2023-rating,
    title = "Rating Short {L}2 Essays on the {CEFR} Scale with {GPT}-4",
    author = "Yancey, Kevin P.  and
      Laflair, Geoffrey  and
      Verardi, Anthony  and
      Burstein, Jill",
    editor = {Kochmar, Ekaterina  and
      Burstein, Jill  and
      Horbach, Andrea  and
      Laarmann-Quante, Ronja  and
      Madnani, Nitin  and
      Tack, Ana{\"i}s  and
      Yaneva, Victoria  and
      Yuan, Zheng  and
      Zesch, Torsten},
    booktitle = "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.bea-1.49/",
    doi = "10.18653/v1/2023.bea-1.49",
    pages = "576--584",
    abstract = "Essay scoring is a critical task used to evaluate second-language (L2) writing proficiency on high-stakes language assessments. While automated scoring approaches are mature and have been around for decades, human scoring is still considered the gold standard, despite its high costs and well-known issues such as human rater fatigue and bias. The recent introduction of large language models (LLMs) brings new opportunities for automated scoring. In this paper, we evaluate how well GPT-3.5 and GPT-4 can rate short essay responses written by L2 English learners on a high-stakes language assessment, computing inter-rater agreement with human ratings. Results show that when calibration examples are provided, GPT-4 can perform almost as well as modern Automatic Writing Evaluation (AWE) methods, but agreement with human ratings can vary depending on the test-taker{'}s first language (L1)."
}
@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}
@inproceedings{naismith-etal-2023-automated,
  title = "Automated evaluation of written discourse coherence using {GPT}-4",
  author = "Naismith, Ben  and
    Mulcaire, Phoebe  and
    Burstein, Jill",
  editor = {Kochmar, Ekaterina  and
    Burstein, Jill  and
    Horbach, Andrea  and
    Laarmann-Quante, Ronja  and
    Madnani, Nitin  and
    Tack, Ana{\"i}s  and
    Yaneva, Victoria  and
    Yuan, Zheng  and
    Zesch, Torsten},
  booktitle = "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
  month = jul,
  year = "2023",
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.bea-1.32/",
  doi = "10.18653/v1/2023.bea-1.32",
  pages = "394--403",
  abstract = "The popularization of large language models (LLMs) such as OpenAI{'}s GPT-3 and GPT-4 have led to numerous innovations in the field of AI in education. With respect to automated writing evaluation (AWE), LLMs have reduced challenges associated with assessing writing quality characteristics that are difficult to identify automatically, such as discourse coherence. In addition, LLMs can provide rationales for their evaluations (ratings) which increases score interpretability and transparency. This paper investigates one approach to producing ratings by training GPT-4 to assess discourse coherence in a manner consistent with expert human raters. The findings of the study suggest that GPT-4 has strong potential to produce discourse coherence ratings that are comparable to human ratings, accompanied by clear rationales. Furthermore, the GPT-4 ratings outperform traditional NLP coherence metrics with respect to agreement with human ratings. These results have implications for advancing AWE technology for learning and assessment."
}
% AES Prompting Strategies
@misc{mansour2024largelanguagemodelsautomatically,
  title={Can Large Language Models Automatically Score Proficiency of Written Essays?}, 
  author={Watheq Mansour and Salam Albatarni and Sohaila Eltanbouly and Tamer Elsayed},
  year={2024},
  eprint={2403.06149},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2403.06149}, 
}
@misc{touvron2023llama2openfoundation,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
  author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  year={2023},
  eprint={2307.09288},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2307.09288}, 
}
@inproceedings{mathias-bhattacharyya-2018-asap,
  title = "{ASAP}++: Enriching the {ASAP} Automated Essay Grading Dataset with Essay Attribute Scores",
  author = "Mathias, Sandeep  and
    Bhattacharyya, Pushpak",
  editor = "Calzolari, Nicoletta  and
    Choukri, Khalid  and
    Cieri, Christopher  and
    Declerck, Thierry  and
    Goggi, Sara  and
    Hasida, Koiti  and
    Isahara, Hitoshi  and
    Maegaard, Bente  and
    Mariani, Joseph  and
    Mazo, H{\'e}l{\`e}ne  and
    Moreno, Asuncion  and
    Odijk, Jan  and
    Piperidis, Stelios  and
    Tokunaga, Takenobu",
  booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
  month = may,
  year = "2018",
  address = "Miyazaki, Japan",
  publisher = "European Language Resources Association (ELRA)",
  url = "https://aclanthology.org/L18-1187/"
}
@misc{stahl2024exploringllmpromptingstrategies,
  title={Exploring LLM Prompting Strategies for Joint Essay Scoring and Feedback Generation}, 
  author={Maja Stahl and Leon Biermann and Andreas Nehring and Henning Wachsmuth},
  year={2024},
  eprint={2404.15845},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2404.15845}, 
}
% AES Multi-trait
@inproceedings{banno-etal-2024-gpt,
  title = "Can {GPT}-4 do {L}2 analytic assessment?",
  author = "Bann{\`o}, Stefano  and
    Vydana, Hari K.  and
    Knill, Kate M.  and
    Gales, Mark J. F.",
  editor = {Kochmar, Ekaterina  and
    Bexte, Marie  and
    Burstein, Jill  and
    Horbach, Andrea  and
    Laarmann-Quante, Ronja  and
    Tack, Ana{\"i}s  and
    Yaneva, Victoria  and
    Yuan, Zheng},
  booktitle = "Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)",
  month = jun,
  year = "2024",
  address = "Mexico City, Mexico",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.bea-1.14/",
  pages = "149--164",
  abstract = "Automated essay scoring (AES) to evaluate second language (L2) proficiency has been a firmly established technology used in educational contexts for decades. Although holistic scoring has seen advancements in AES that match or even exceed human performance, analytic scoring still encounters issues as it inherits flaws and shortcomings from the human scoring process. The recent introduction of large language models presents new opportunities for automating the evaluation of specific aspects of L2 writing proficiency. In this paper, we perform a series of experiments using GPT-4 in a zero-shot fashion on a publicly available dataset annotated with holistic scores based on the Common European Framework of Reference and aim to extract detailed information about their underlying analytic components. We observe significant correlations between the automatically predicted analytic scores and multiple features associated with the individual proficiency components."
}
@misc{beltagy2020longformerlongdocumenttransformer,
  title={Longformer: The Long-Document Transformer}, 
  author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
  year={2020},
  eprint={2004.05150},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2004.05150}, 
}
@misc{do2024autoregressivescoregenerationmultitrait,
  title={Autoregressive Score Generation for Multi-trait Essay Scoring}, 
  author={Heejin Do and Yunsu Kim and Gary Geunbae Lee},
  year={2024},
  eprint={2403.08332},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2403.08332}, 
}
@misc{raffel2023exploringlimitstransferlearning,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
  author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  year={2023},
  eprint={1910.10683},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1910.10683}, 
}
@misc{lee2024unleashinglargelanguagemodels,
  title={Unleashing Large Language Models' Proficiency in Zero-shot Essay Scoring}, 
  author={Sanwoo Lee and Yida Cai and Desong Meng and Ziyang Wang and Yunfang Wu},
  year={2024},
  eprint={2404.04941},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2404.04941}, 
}
@misc{chu2025rationaleessayscoresenhancing,
  title={Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay Scoring with Rationale Generated by LLMs}, 
  author={SeongYeub Chu and JongWoo Kim and Bryan Wong and MunYong Yi},
  year={2025},
  eprint={2410.14202},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2410.14202}, 
}
@misc{eltanbouly2025tratestraitspecificrubricassistedcrossprompt,
  title={TRATES: Trait-Specific Rubric-Assisted Cross-Prompt Essay Scoring}, 
  author={Sohaila Eltanbouly and Salam Albatarni and Tamer Elsayed},
  year={2025},
  eprint={2505.14577},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2505.14577}, 
}

%%%% LLM Interpretable Features %%%%
@misc{mcinerney2023chillzeroshotcustominterpretable,
  title={CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models}, 
  author={Denis Jered McInerney and Geoffrey Young and Jan-Willem van de Meent and Byron C. Wallace},
  year={2023},
  eprint={2302.12343},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2302.12343}, 
}
@misc{benara2024craftinginterpretableembeddingsasking,
  title={Crafting Interpretable Embeddings by Asking LLMs Questions}, 
  author={Vinamra Benara and Chandan Singh and John X. Morris and Richard Antonello and Ion Stoica and Alexander G. Huth and Jianfeng Gao},
  year={2024},
  eprint={2405.16714},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2405.16714}, 
}
@misc{balek2025llmbasedfeaturegenerationtext,
  title={LLM-based feature generation from text for interpretable machine learning}, 
  author={Vojtěch Balek and Lukáš Sýkora and Vilém Sklenák and Tomáš Kliegr},
  year={2025},
  eprint={2409.07132},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2409.07132}, 
}
@misc{sam2025predictingperformanceblackboxllms,
  title={Predicting the Performance of Black-box LLMs through Self-Queries}, 
  author={Dylan Sam and Marc Finzi and J. Zico Kolter},
  year={2025},
  eprint={2501.01558},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2501.01558}, 
}